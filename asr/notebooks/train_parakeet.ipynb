{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3244f846-7eb8-43c8-8bbd-f948e35fbb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raid/miniconda3/envs/cloud-removal/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA available: True CUDA version: 12.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import glob\n",
    "import subprocess\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from omegaconf import OmegaConf, DictConfig, open_dict\n",
    "from nemo.core.config import hydra_runner\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "# Correct import\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "print(\"PyTorch CUDA available:\", torch.cuda.is_available(), \"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "# Download and prepare AN4 data (same as before)\n",
    "DATA_DIR = os.getcwd() + \"/files\"\n",
    "# DATA_DIR = os.getcwd() + \"/asr/notebooks/files/\"\n",
    "os.environ[\"DATA_DIR\"] = DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2542d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxi, mini = (73.038375, 1.33225)\n",
    "maxi, mini = (45, 1.33225)\n",
    "\n",
    "# Create training configuration\n",
    "train_config = DictConfig({\n",
    "    'manifest_filepath': f'{DATA_DIR}/train_manifest.json',\n",
    "    'sample_rate': 16000,\n",
    "    'batch_size': 2,  # Reduced batch size for stability\n",
    "    'shuffle': True,\n",
    "    'num_workers': 2,  # Reduced for stability\n",
    "    'pin_memory': True,\n",
    "    'trim_silence': True,\n",
    "    'max_duration': maxi,\n",
    "    'min_duration': mini,\n",
    "    \"trim\": True,\n",
    "})\n",
    "\n",
    "val_config = DictConfig({\n",
    "    'manifest_filepath': f'{DATA_DIR}/test_manifest.json',\n",
    "    'sample_rate': 16000,\n",
    "    'batch_size': 4,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': True,\n",
    "     \"trim\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f4494f-4335-43b1-a92b-8b04f39d2895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-05 10:33:00 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-06-05 10:33:01 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_lhotse: true\n",
      "    skip_missing_manifest_entries: true\n",
      "    input_cfg: null\n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    text_field: answer\n",
      "    batch_duration: null\n",
      "    use_bucketing: true\n",
      "    bucket_duration_bins: null\n",
      "    bucket_batch_size: null\n",
      "    num_buckets: 30\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2025-06-05 10:33:01 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_lhotse: true\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    max_duration: 40.0\n",
      "    min_duration: 0.1\n",
      "    num_workers: 2\n",
      "    pin_memory: true\n",
      "    text_field: answer\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-05 10:33:01 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2025-06-05 10:33:05 nemo_logging:393] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
      "[NeMo I 2025-06-05 10:33:05 nemo_logging:393] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
      "[NeMo I 2025-06-05 10:33:05 nemo_logging:393] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
      "[NeMo I 2025-06-05 10:33:08 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from /home/raid/cognition/til/asr/notebooks/parakeet-tdt-0.6b-v2/parakeet-tdt-0.6b-v2.nemo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncDecRNNTBPEModel(\n",
       "  (preprocessor): AudioToMelSpectrogramPreprocessor(\n",
       "    (featurizer): FilterbankFeatures()\n",
       "  )\n",
       "  (encoder): ConformerEncoder(\n",
       "    (pre_encode): ConvSubsampling(\n",
       "      (out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
       "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pos_enc): RelPositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x ConformerLayer(\n",
       "        (norm_feed_forward1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward1): ConformerFeedForward(\n",
       "          (linear1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (activation): Swish()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "        (norm_conv): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): ConformerConvolution(\n",
       "          (pointwise_conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (depthwise_conv): CausalConv1D(1024, 1024, kernel_size=(9,), stride=(1,), groups=1024, bias=False)\n",
       "          (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Swish()\n",
       "          (pointwise_conv2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (norm_self_att): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attn): RelPositionMultiHeadAttention(\n",
       "          (linear_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (linear_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (linear_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (linear_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_pos): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (norm_feed_forward2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward2): ConformerFeedForward(\n",
       "          (linear1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (activation): Swish()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm_out): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): RNNTDecoder(\n",
       "    (prediction): ModuleDict(\n",
       "      (embed): Embedding(1025, 640, padding_idx=1024)\n",
       "      (dec_rnn): LSTMDropout(\n",
       "        (lstm): LSTM(640, 640, num_layers=2, dropout=0.2)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (joint): RNNTJoint(\n",
       "    (pred): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (enc): Linear(in_features=1024, out_features=640, bias=True)\n",
       "    (joint_net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=640, out_features=1030, bias=True)\n",
       "    )\n",
       "    (_loss): RNNTLoss(\n",
       "      (_loss): TDTLossNumba()\n",
       "    )\n",
       "    (_wer): WER()\n",
       "  )\n",
       "  (loss): RNNTLoss(\n",
       "    (_loss): TDTLossNumba()\n",
       "  )\n",
       "  (spec_augmentation): SpectrogramAugmentation(\n",
       "    (spec_augment): SpecAugment()\n",
       "  )\n",
       "  (wer): WER()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model .from_pretrained\n",
    "# model = nemo_asr.models.EncDecRNNTBPEModel.restore_from(\"parakeet-tdt-0.6b-v2.nemo\")\n",
    "# model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(\"parakeet-tdt-0.6b-v2.nemo\")\n",
    "\n",
    "# model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v2\")\n",
    "model = nemo_asr.models.ASRModel.restore_from(\"parakeet-tdt-0.6b-v2/parakeet-tdt-0.6b-v2.nemo\")\n",
    "# model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b995399-b102-4057-8d95-42fc24e006a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "from lightning.pytorch import LightningModule\n",
    "print(isinstance(model, LightningModule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3020ec-e03e-4344-9839-f669f774a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-05 10:33:08 nemo_logging:393] Dataset loaded with 4500 files totalling 31.91 hours\n",
      "[NeMo I 2025-06-05 10:33:08 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-06-05 10:33:09 nemo_logging:393] Dataset loaded with 8 files totalling 0.06 hours\n",
      "[NeMo I 2025-06-05 10:33:09 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "# Set up training and validation data\n",
    "model.setup_training_data(train_config)\n",
    "model.setup_validation_data(val_config)\n",
    "\n",
    "# Optional but recommended: prepare the model\n",
    "# model.prepare_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b039055-07ae-4c6f-8d3f-f59e8b9084d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_dict(model.cfg.optim):\n",
    "    model.cfg.optim.lr = 1e-4\n",
    "    model.cfg.optim.sched.warmup_steps = 200\n",
    "    model.cfg.optim.sched.warmup_ratio = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cabbef-9a5a-4dcc-9a35-feecf5c928fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Set up logger\n",
    "tb_logger = TensorBoardLogger(save_dir=\"./tb_logs\", name=\"parakeet_finetune\")\n",
    "\n",
    "# Checkpoint and early stopping on val_wer\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_wer\", mode=\"min\", save_top_k=1,\n",
    "    dirpath=\"./checkpoints\", filename=\"best_val_wer\"\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_wer\", mode=\"min\", patience=5\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    precision=\"bf16\",\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=[1],\n",
    "    accumulate_grad_batches=16,\n",
    "    logger=tb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4c824-7ace-4eb1-ae50-48746b009f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(model)\n",
    "# trainer.fit(model, ckpt_path=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182bec78-5580-4e01-9cf9-381377a67fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_to('ft-parakeet-tdt-0.6b-v2-e20.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "096c3b9b-2046-4561-b6bf-6142fff8d90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params | Mode \n",
       "--------------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
       "1 | encoder           | ConformerEncoder                  | 608 M  | train\n",
       "2 | decoder           | RNNTDecoder                       | 7.2 M  | train\n",
       "3 | joint             | RNNTJoint                         | 1.7 M  | train\n",
       "4 | loss              | RNNTLoss                          | 0      | train\n",
       "5 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
       "6 | wer               | WER                               | 0      | train\n",
       "--------------------------------------------------------------------------------\n",
       "617 M     Trainable params\n",
       "0         Non-trainable params\n",
       "617 M     Total params\n",
       "2,471.304 Total estimated model params size (MB)\n",
       "706       Modules in train mode\n",
       "0         Modules in eval mode"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1da5e-b000-4a3f-8570-1457043dcfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
